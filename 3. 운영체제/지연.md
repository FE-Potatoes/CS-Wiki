# 지연

## 운영 체제

### 1. 운영체제와 컴퓨터

컴퓨터의 자원들을 효율적으로 관리하며 사용자가 컴퓨터를 편리하게 사용할 수 있는 환경을 제공하는 여러 프로그램의 모임(시스템 소프트웨어 일종)

운영체제 역할

- CPU 스케줄링과 프로세스 관리
- 메모리 관리
- 디스크 파일 관리
- I/O 디바이스 관리

운영체제 구조
유저 프로그램 - **인터페이스(GUI/CUI) - 시스템콜 - 커널(드라이버, 파일 시스템)** - 하드웨어

시스템콜
운영체제가 커널에 접근하기 위한 인터페이스 (추상화 계층)
유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 사용
컴퓨터 자원에 대한 직접 접근을 차단할 수 있고, 프로그램을 다른 프로그램으로부터 보호함
유저 프로그램이 I/O 요청으로 트랩 발동 -> 시스템콜을 통해 커널 모드 변환 실행 -> 처리 후 유저 모드 복귀
** 보안/안정성 문제로 인해 유저 프로그램은 직접 하드웨어를 제어할 수 없으며, 운영체제 커널을 통해 처리 **

modebit
시스템콜이 작동될 때 modebit을 참고해 유저 모드와 커널 모드 구분 (0 커널 / 1 유저)

컴퓨터의 요소
CPU + DMA 컨트롤러 + 메모리 + 타이머 + 디바이스 컨트롤러 등으로 구성

CPU
Central Processing Unit
인터럽트(컴퓨터 시스템에서 CPU의 실행 흐름을 일시적으로 중단하고, 외부 또는 내부 이벤트에 의해 특정 작업을 처리하도록 하는 메커니즘)에 의해 단순히 메모리에 존재하는 명령어를 해석해서 실행 -> 커널이 프로그램을 메모리에 올려 프로세스로 만들면 CPU가 처리

- 제어장치 (CU, Control Unit)
  입출력장치 간 통신을 제어하고 명령어를 읽고 해석해 데이터 처리를 위한 순서를 결정
- 레지스터
  임시기억장치로, CPU와 직접 연결되어 연산 속도가 메모리보다 월등히 빠름
  CPU가 자체적으로 데이터를 저장할 수 없기 때문에 레지스터를 거치게 됨
  CPU는 가능한 산을 빠르게 처리하기 위해 가능한 한 많은 데이터를 레지스터에서 처리
  데이터가 너무 크거나 계산을 위한 데이터가 많을 경우, CPU는 메모리에서 처리
- 산술논리연산장치(ALU, Arithmetic Logic Unit)
  덧셈, 뺄셈 같은 두 숫자의 산술 연산, 배타적 논리합, 논리곱 같은 논리 연산을 계산하는 디지털 회로

CPU 연산 처리
제어장치가 메모리/레지스터에 계산할 값 업로드 -> 제어장치는 레지스터에 있는 값을 계산하라고 산술논리연산장치에 명령 -> 제어장치가 계산 값을 메모리로 저장

DMA 컨트롤러
I/O 디바이스가 메모리에 직접 접근할수 있도록 하는 하드웨어 장치
CPU의 부하를 막아주며, 일을 보조

메모리
전자회로에서 데이터나 상태, 명령어 등을 기록하는 장치
RAM(Random Access Memory)를 일컬어 부름

타이머
특정 프로그램에 시간 제한을 다는 역할
시간이 많이 걸리는 프로그램이 작동할 때 제한을 걸기 위해 존재

디바이스 컨트롤러
IO 디바이스와 CPU 간의 데이터 전송 및 통신을 관리하는 하드웨어 장치
직접 통신을 제한해 효율적이고 안정적인 입출력 작업을 수행할 수 있도록 함

### 2. 메모리

메모리 계층
레지스터 - 캐시(L1, L2, L3 캐시) - 메모리(RAM)/주기억장치 - 저장장치(HDD, SSD)/보조기억장치

캐시
데이터를 미리 복사해 놓는 임시 저장소, 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
L1 (CPU 내부, 가장 빠름, 가장 작음) , L2 (대부분 CPU 내부, L1보다 느림, L1보다 큼), L3 (CPU 외부, 가장 큼)
\*\* CPU와 캐시 컨트롤러가 캐시 저장 위치를 컨트롤함

캐싱 계층을 두는 경우
속도 차이를 해결하기 위해 계층과 계층 사이에 있는 계층
메모리와 CPU 사이의 속도 차이가 크기 때문에 중간에 레지스터 계층을 두고 속도 차이를 해결

캐시를 직접 설정하는 경우
자주 사용하는 데이터의 시간 지역성(최근 사용한 데이터에 재접근하려는 특성) + 공간 지역성(최근 접근한 데이터를 이루는 공간이나 가까운 공간에 접근하는 특성)

캐시히트
CPU가 데이터를 요청했을 때, 캐시에서 원하는 데이터를 찾은 경우
CPU 내부 버스를 기반으로 작동하기에 속도가 빠름

캐시미스
캐시히트에 실패했을 때, 메모리에서 원하는 데이터를 찾아오는 경우
CPU 외부 버스를 기반으로 작동하기에 속도가 느림

캐시매핑
캐시가 히트되기 위해 매핑하는 방법, CPU의 레지스터와 RAM 간에 데이터를 주고 받을 때를 기반으로 함

- 직접 매핑
  - 위치 기반으로 매핑
  - 충돌 발생이 잦음
- 연관 매핑
  - 주 메모리의 각 블록은 캐시의 모든 슬롯에 매핑 가능
  - 캐시 컨트롤러가 비어있는 슬롯에 자유롭게 매핑
  - 충돌이 적고 유연성이 높음
- 집합 연관 매핑
  - 연관 매핑과 직접 매핑의 절충형
  - 캐시를 여러 개의 집합으로 나눠 순서를 일치시키되, 내부에서는 연관 매핑

웹 브라우저 캐시

- 쿠키
  - 만료기한이 있는 키-값 저장소(4KB)
  - 동일 브라우저 상에서 쿠키를 공유할 수 있음 (same site = strict, 공유X)
  - document.cookie로 쿠키값에 접근하는 것을 방지하기 위해 httponly 옵션 설정 필요
- 로컬 스토리지
  - 만료기한이 없는 키-값 저장소(5MB)
  - 브라우저를 닫아도 유지되며 클라이언트에서만 수정 가능
- 세션 스토리지
  - 만료기한이 없는 키-값 저장소(5MB)
  - 탭 단위로 생성하며, 탭을 닫을 때 데이터가 삭제됨
  - 클라이언트에서만 수정 가능

가상 메모리
컴퓨터 프로그램이 사용하는 주소 공간을 운영 체제가 관리하는 방식

페이지 폴트
프로세스 주소 공간(디스크)에는 존재하나 RAM에는 존재하지 않는 경우 발생

스와핑
RAM에서 당장 사용되지 않는 영역을 디스크로 잠시 옮기는 것

프로그램 실행 시 동작의 흐름

1. 사용자가 메모장.exe 실행 -> 실행 요청이 운영체제에 전달됨
2. 운영체제가 디스크에서 메모장.exe 파일을 읽음
3. 해당 프로그램을 위한 새로운 프로세스를 생성
   → 운영체제는 새로운 가상 주소 공간을 이 프로세스에 부여
4. RAM에 프로그램의 코드/데이터 일부를 적재 (로드)→ 완전히 다 올리는 게 아니라, 처음 필요한 부분만 올림 (지연 로딩)
5. 가상 주소 ↔ 실제 RAM 주소를 매핑하는 페이지 테이블 생성→ 가상 주소 0x0000에는 실제 RAM 0xA000이 매핑되는 식으로 초기화됨
6. 프로그램이 가상 주소로 메모리에 접근 시도→ CPU가 MMU(메모리 관리 유닛)를 통해 페이지 테이블을 참조함
7. 해당 가상 주소에 매핑된 실제 주소가 존재하는지 확인
   - 존재: 실제 RAM 주소로 접근 (TLB → 페이지 테이블)
   - 존재X:→ 페이지 폴트(Page Fault) 발생→ 운영체제가 디스크에서 해당 페이지를 읽어와 RAM에 로드→ 페이지 테이블 갱신 (새로운 매핑 추가)

스레싱
메모리의 페이지 폴트율(디스크에서 데이터 값을 RAM으로 가져옴)이 높은 것으로, 성능 저하를 초래함
메모리에 프로세스가 올라가고, 해당 처리 진행중에 페이지 폴트가 일어나면 CPU의 대기 시간이 생김
-> 이는 CPU가 일을 한한다고 생각하고, 가용성을 높이기 위해 메모리 위에 더 많은 프로세스를 올림

스레싱 해결 방법

- 작업 세트(프로세스의 지역성을 통해 페이지 집합을 만들어 미리 메모리에 로드)
- PFF(Page Fault Frequency, 상한선과 하한선을 두고 프레임을 조절)

메모리 할당
시작 메모리 위치, 메모리 할당 크기 기반

연속 할당

- 고정 분할 방식
  메모리를 미리 나누어 관리, 융통성X, 내부 단편화 발생
- 가변 분할 방식
  매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눔, 외부 단편화(메모리 할당-종료-쪼개진 공간 사이즈 유지) 발생

불연속 할당
현대 운영체제가 쓰는 방법

- 페이징 기법
  메모리를 동일한 크기의 페이지로 나누고, 프로그램마다 페이지 테이블을 두어 메모리에 프로그램을 할당하는 것
- 세그멘테이션
  페이지 단위가 아닌 의미 단위로 나눔 (코드, 데이터, 스택, 힙 영역 등)
- 페이지드 세그멘테이션
  프로그램을 의미 단위인 세그먼트로 나눠, 동일 크기의 페이지 단위로 나누는 것

페이지 교체 알고리즘
메모리의 공간 한정으로 인해 스와핑이 발생하는데 사용됨

- 오프라인 알고리즘
  먼 미래에 활용될 페이지와 현재 활용할 페이지를 교환하는 방법 (실제로 사용 불가)
- FIFO
  가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
- LRU (Least Recently Used)
  참조가 가장 오래된 페이지 교환
- NUR (Not Used Recently)
- LFU (Least Frequently Used)

### 3. 프로세스와 스레드

프로세스 : 컴퓨터에서 실행되고 있는 프로그램, CPU 스케쥴링의 대상이 되는 task와 같은 의미
스레드 : 프로세스 내 작업의 흐름

프로그램이 메모리에 올라가면 -> 프로세스가 되는 인스턴스화 발생 -> 운영체제의 CPU 스케줄러에 따라 CPU가 프로세스 실행

프로그램을 만드는 과정

- 소스 코드 파일 전처리
- 컴파일러를 통해 어셈블리어로 변환
- 어셈블리어를 목적 코드로 변환
- 프로그램 내 라이브러리 함수 또는 다른 파일들과 목적 코드를 결합해 실행 파일 생성

프로세스의 상태

- 생성 상태
  프로세스가 생성된 상태
- 대기 상태
  메모리 할당/비할당 대기 상태로 CPU 스케줄러로부터 CPU 소유권이 넘어오기를 기다리는 상태
- 대기 중단 상태
  메모리 부족으로 일시 중단된 상태
- 실행 상태
  CPU 소유권과 메모리를 할당 받아 인스트럭션을 수행중인 상태 (CPU Burst)
- 중단 상태
  프로세스가 차단된 상태
  ex. I/O 디바이스에 의한 인터럽트(프린트 버튼 클릭)
- 일시 중단 상태
  중단 상태에서 프로세스를 실행하고자 했으나 메모리 부족으로 일시 중단된 상태
- 종료 상태
  메모리와 CPU 소유권 해제 상태

프로세스의 메모리 구조
동적 영역
런타임 단계에서 메모리를 할당 받음

- 스택
  지역 변수, 매개변수, 실행되는 함수에 의해 늘어들거나 줄어드는 메모리 영역
  함수가 호출될 때마다 관련 정보가 스택에 계속 저장됨
  위 주소부터 할당
- 힙
  동적으로 할당되는 변수를 담음
  아래 주소부터 할당

정적 영역
컴파일 단계에서 메모리를 할당함

- 데이터 영역
  BSS segment(0이나 값이 없는 변수 할당), Data segment(0이 아닌 값으로 초기화된 변수 할당), code segment(프로그램의 코드)

PCB (Process Control Block)

- 운영체제에서 프로세스에 대한 메타데이터를 저장한 데이터로, 프로세스 생성 시 해당 PCB 생성
- 일반 사용자가 접근하지 못하도록 커널 스택의 가장 앞부분에서 관리됨

컨텍스트 스위칭 (Context Switching)

- PCB 기반으로 프로세스의 상태를 저장하고 로드시키는 과정
- 한 프로세스에 할당된 시간이 끝나거나 인터럽트에 의해 발생됨
  -> PCB 저장 및 로드에 따라 유휴 시간 및 캐시 미스 발생

멀티프로세싱

- 멀티프로세스를 통해 동시에 두 가지 이상의 일을 수행할 수 있는 것
- 병렬적으로 일을 처리할 수 있으며, 특정 프로세스에 문제가 발생해도 다른 프로세스를 이용할 수 있음

IPC (Inter Process Communication)
프로세스까리 데이터를 주고받고 공유 데이터를 관리하는 메커니즘
ex/ 클라이언트 - 서버 간 데이터 요청 및 응답

IPC 종류

- 공유 메모리
  기본적으로는 각 프로세스의 메모리를 다른 프로세스가 접근할 수 없음
  공유 메모리를 통해 여러 프로세스가 하나의 메모리를 공유함
  필요한 데이터 복사의 오버헤드가 발생하지 않고, 동기화가 필요함
- 파일
  디스크에 저장된 데이터 또는 파일 서버에서 제공한 데이터
- 소켓
  동일 컴퓨터의 다른 프로세스나 네트워크의 다른 컴퓨터로 네트워크 인터페이스를 통해 전송하는 데이터
  TCP, UDP 존재
- 익명 파이프
  프로세스 간 FIFO 방식으로 읽히는 임시 공간인 파이프를 기반으로 데이터를 주고 받음
  단방향의 읽기/쓰기 전용 파이프를 생성
- 명명된 파이프
  파이프 서버와 하나 이상의 파이프 클라이언트 간의 통신을 위한 명명된 단방향 또는 양방향 파이프
- 메시지 큐
  메시지를 큐 데이터 구조 형태로 관리하는 것
  커널에서 전역적으로 관리되며 다른 방식보다 사용 방법이 직관적이고 간단함

스레드
프로세스와 달리 코드, 데이터, 힙을 공유

멀티스레딩
프로세스 내 작업을 여러 개의 스레드로 처리하며, 자원을 공유하기 때문에 효율성이 높음
한 스레드에 문제가 생기면 다른 스레드에도 영향을 끼쳐 프로세스에 영향을 줄 수 있음

공유 자원(shared resource)
시스템 안에서 각 프로세스, 스레드가 함께 접근할 수 있는 모니터, 프린터, 메모리, 파일, 데이터 등의 자원이나 변수
두 개 이상의 프로세스가 동시에 읽거나 쓰는 상황 ‘경쟁 상태’ -> 결과에 영향을 미칠 수 있음

임계 영역(critical section)
둘 이상의 프로세스, 스레드가 공유 자원에 접근할 때 순서 등의 이유로 결과가 달라지는 코드 영역

임계 영역을 해결하는 방법
상호 배제(임계 영역 내 프로세스는 하나만 들어갈 수 있음), 한정 대기(특정 프로세스가 임계 영역에 들어가지 못하면 안됨), 융통성(임계 영역이 비어 있을 경우, 어떤 프로세스도 들어갈 수 있기에 방해X) 조건을 만족

- 뮤텍스
  ’lock() -> unlock()’ 잠금 설정 및 해제 하는 객체
- 세마포어
  정수 값과 두 가지 함수 wait(), signal()로 공유 자원에 대한 접근 처리
  바이너리 세마포어, 카운팅 세마포어 ..
- 모니터
  둘 이상의 스레드나 프로세스가 공유 자원에 안전하게 접근할 수 있도록 공유 자원을 숨기고 해당 접근에 대해 인터페이스만 제공

교착 상태
두 개 이사의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태
상호 배제, 점유 대기, 비선점, 환형 대기 만족 시 교착 상태가 발생할 수 있음

### 4. CPU 스케줄링 알고리즘

비선점형 방식(non-preemptive)

- 프로세스가 스스로 CPU 소유권을 포기하는 방식
- 컨텍스트 스위칭으로 인한 부하가 적음

비선점형 방식 종류

- FCFS (First Come, First Served)
  가장 먼저 온 것을 가장 먼저 처리하며, 준비 큐에서의 오랜 대기 현상이 발생함
- SJF (Shortest Job First)
  실행 시간이 가장 짧은 프로세스를 가장 먼저 실행하는 알고리즘
  긴 시간을 가진 프로세스가 실행되지 않는 현상이 일어나며, 평균 대기 시간이 가장 짧음
- 우선순위
  SJF의 단점을 보완해 오래된 작업일수록 우선순위를 높이는 방법을 활용

선점형 방식(preemptive)

- 현대 운영체제가 쓰는 방식
- 지금 사용하고 있는 프로세스를 알고리즘에 의해 중단시키고 강제로 다른 프로세스에 CPU 소유권 할당

선점형 방식 종류

- 라운드 로빈
  각 프로세스에 동일한 할당 시간을 주고, 시간 내 종료되지 않으면 다시 준비 큐의 뒤로 가는 알고리즘
- SRF (Shortest Remaining Time First)
  기존 짧은 작업 수행 중간에 더 짧은 작업이 들어오면 수행하던 프로세스를 중지하고 해당 프로세스를 수행
- 다단계 큐
  우선순위에 따른 준비 큐를 여러 개 사용하고, 큐마다 라운드 로빈, FCFS 등 다른 스케줄링 알고리즘 적용

# 3.1 운영체제와 컴퓨터

### 3.1.1 운영체제의 역할과 구조

<img width="327" alt="image" src="https://github.com/user-attachments/assets/115957f3-5799-4b76-af56-e510df46cc47" />


- 운영체제의 역할
    1. CPU 스케줄링과 프로세스 관리: 어떤 프로세스에 CPU를 할당/반환할지
    2. 메모리 관리: 어떤 프로세스에 메모리를 할당할지
    3. 디스크 파일 관리: 디스크 파일을 어떤 방법으로 보관할지
    4. I/O 디바이스 관리: I/O 디바이스와 컴퓨터 간 데이터 교환 관리

- sys call
    - 유저모드에서 커널모드로 전환하기 위한 명령어
    - 유저모드에서 직접적으로 파일을 읽지 않고, 커널모드에서 파일을 읽고 다시 유저 모드로 돌아가 그 이후 유저 프로그램의 로직을 수행함
    → 컴퓨터 자원에 대한 직접 접근 차단. 프로그램의 독립적인 실행 가능
        - 왜 유저모드에서 직접적으로 파일을 읽으면 안될까? 공격자가 임의로 내용을 조작할 수 있기 때문
    - cf) 유저모드: 유저가 접근할 수 있는 영역을 제한적으로 두며, 컴퓨터 자원에 함부로 침범하지 못 하는 모드
    - cf) 커널모드: 모든 컴퓨터 자원에 접근할 수 있는 모드. 메모리, 프로세스, 파일 시스템, I/O 관리 등 가능
    
- modebit
    - 0/1 값을 가지는 플래그 변수 (0 - 커널모드, 1 - 유저모드)
    

### 3.1.2 컴퓨터의 요소

- CPU
    - 산술논리연산장치, 제어장치, 레지스터로 구성
    - 인터럽트에 의해 실행된 메모리에 존재하는 명령어를 해석해서 실행
    - 산술논리연산장치
        - 인터럽트: 특정 신호에 의해 CPU를 잠시 정지시키는 행위
            1. 하드웨어 인터럽트(I/O 인터럽트): CPU가 아닌 다른 하드웨어 장치가 CPU 서비스를 요청하는 경우 발생
            2. 소프트웨어 인터럽트(trap): 소프트웨어(사용자 프로그램)이 발생시키는 인터럽트
    - 제어장치
        - 프로세스 조작을 지시하는 CPU의 한 부품
        - I/O 장치들의 통신 제어 & 데이터 처리를 위한 순서 결정
    - 레지스터
        - CPU 내부에 위치한 임시기억장치
        - CPU와 직접 연결되어 있어 연산 속도가 메모리보다 빠름
    - CPU 연산 처리
        
        <img width="464" alt="image" src="https://github.com/user-attachments/assets/2c87ce70-098d-41bf-94df-7cd5abf6ecad" />

        

- DMA 컨트롤러
    - I/O 디바이스가 메모리에 직접 접근할 수 있게 해주는 하드웨어 장치
    - CPU가 받는 인터럽트 요청을 함께 부담하여 CPU 부하를 막음

- 메모리(RAM)
    - 전자회로에서 데이터, 상태, 명령어 등을 기록하는 장치

- 타이머
    - 작업 실행 단위 시간을 정하는 역할
    - 실행 시간이 오래 걸리는 경우, 컨텍스트 스위칭 실시

- 디바이스 컨트롤러
    - 컴퓨터와 연결되어 있는 I/O 디바이스들의 작은 CPU

### 3.2.1 메모리 계층

<img width="704" alt="image" src="https://github.com/user-attachments/assets/bd0b3bda-7ef5-4f5c-a532-d1e6a9e6931f" />


- 위 계층으로 올라갈수록 용량은 작아지고, 속도는 빨라짐
- 계층이 분리되어 있는 이유: 계층별로 접근 전략이 다름. 속도/비율/전력 효율을 위해 계층을 나눠서 접근함

- 캐시
    - 데이터를 미리 복사해놓는 임시 저장소
    - 빠른 장치와 느린 장치의 속도 차이에 따른 병목 현상을 줄이기 위한 메모리
    - 캐시를 통해, 데이터에 접근하는 시간이 오래 걸리는 경우를 해결하고 다시 계산하는 시간을 절약할 수 있음
    - 캐싱 설정 근거
        1. 시간지역성(Temporal locality): 최근에 사용한 데이터에 다시 접근하려는 특성
        2. 공간지역성(Spatial Locality): 최근에 접근한 데이터를 이루고 있는 공간이나 그 가까운 공간에 접근하는 특성
    - 캐시히트: 캐시에 원하는 데이터가 저장되어 있는 경우
    - 캐시미스: 캐시에 원하는 데이터가 없는 경우 → RAM에서 데이터 가져와야 함. 시간 증가
    - 웹브라우저의 캐시
        1. 쿠키
        2. 로컬 스토리지
        3. 세션 스토리지

- 가상 메모리
    - 디스크의 일부 공간을 RAM처럼 활용하는 기법 → 모든 데이터를 물리 메모리에 올리지 않고, 필요한 부분만 RAM에 올려서 실행 (Demand Paging)
    - 컴퓨터가 가진 물리적 메모리 공간보다 더 많은 메모리를 사용할 수 있도록 가상 주소 공간을 제공하는 메모리 관리 기법
    - 필요한 이유
        1. 물리적 메모리(RAM) 한계 극복 → 대용량 프로그램이나 데이터 실행 가능
        2. 프로세스 격리 및 메모리 보호: 프로세스마다 독립적인 가상 주소 공간을 제공하여 프로세스가 다른 메모리에 잘못 접근하는 것을 방지함
    - 장점
        - 페이지 교체 알고리즘을 통한 성능 최적화
        - 프로그램 실행 중단 방지: 물리적 메모리가 부족한 상황이더라도, 가상 메모리를 통해 필요한 데이터를 디스크에서 가져와 계속 실행할 수 있음

- 페이지 폴트
    - CPU가 참조하려는 가상 메모리 주소에 해당하는 데이터가 RAM에 없을 때 발생하는 이벤트
    - 과정
        1. CPU가 가상 주소 참조
        2. TLB 확인 → TLB hit이라면 물리 주소 사용하여 메모리 참조
        3. 없으면 메인 메모리의 페이지 테이블 참조
        4. 없으면 페이지 폴트 발생
        5. 디스크에서 페이지를 읽어옴
        6. 빈 프레임이 존재하면 그냥 넣고 아니면 페이지 교체 알고리즘에 의해 교체할 페이지 선정
        7. 새 페이지를 메모리에 올리고 페이지 테이블 갱신
    - 스레싱: 프로세스가 실제 작업은 거의 하지 못하고, 페이지 폴트 처리만 반복적으로 발생하는 상태
        - 스레싱 증상
            1. CPU 사용량 감소
            2. I/O 증가
        - 발생하는 이유
            1. 프로세스 워킹 셋(작업 세트)이 너무 큰 경우: 자주 접근하는 페이지 수가 RAM보다 큰 경우 계속 페이지 폴트 발생
            2. 페이지 교체 알고리즘이 비효율적인 경우
            3. RAM 부족: 동시에 많은 프로세스가 실행되어 메모리 요구량 급증
        - 해결 방법
            1. RAM 용량 증가. HDD → SSD 변경
            2. 워킹 셋 사용
            3. PFF를 사용하여 페이지 폴트 빈도 조절: 상한선 도달시 프레임 수 증가. 하한선 도달 시 프레임 수 감소

### 메모리 할당 방식

- 연속 할당 (Contiguous Allocation)
    - 메모리 공간을 **연속된 블록**으로 할당
    
    1. 고정 분할 방식
    
    - 메모리를 **고정된 크기의 블록들로 나눔**
    - 프로세스는 적절한 크기의 블록 하나를 점유
    - 장점: 구현이 간단
    - 단점: 내부 단편화 발생 (프로세스 크기보다 블록이 클 경우 낭비)
    
    2. 가변 분할 방식
    
    - 프로세스 요청 크기에 따라 **동적으로 메모리 블록 생성**
    - 장점: 메모리 낭비 적음
    - 단점: 외부 단편화 발생 (여러 개의 작은 빈 공간이 생김)
      
- 불연속 할당 (Non-Contiguous Allocation)
    - 프로세스가 사용하는 메모리 공간이 **물리적으로 떨어져 있어도 됨**
    
    1. 페이징 (Paging)
    
    - 가상 주소 공간과 물리 메모리를 **고정된 크기 페이지로 분할**
    - 페이지 테이블로 각 페이지의 물리적 위치 관리
    - 장점: 외부 단편화 없음
    - 단점: 페이지 테이블 관리 필요
    
    2. 세그멘테이션 (Segmentation)
    
    - 프로세스 메모리를 의미 단위(세그먼트)로 나눔 (ex: 코드, 데이터, 스택 등)
    - 세그먼트마다 크기가 다름
    - 장점: 프로그램 구조와 유사
    - 단점: 외부 단편화 발생
    
    3. 페이지드 세그멘테이션 (Paged Segmentation)
    
    - 세그먼트 내부를 다시 페이지로 나눔
    - 세그멘테이션의 유연성과 페이징의 단편화 해결 능력을 결합

- 페이지 교체 알고리즘
    
    1. FIFO (First-In First-Out)
    
    - 가장 **먼저 들어온 페이지를 먼저 교체**
    - 큐 형태로 페이지를 관리
    - 구현은 간단하지만, 오래됐다고 꼭 안 쓰는 건 아닐 수 있어 **성능이 나쁠 수 있음**
    
    2. LRU (Least Recently Used)
    
    - 가장 **오랫동안 사용되지 않은 페이지를 교체**
    - 과거의 접근 시간을 기반으로 판단
    - 구현 방법: 해시테이블 + 이중연결리스트
        - 해시테이블: 해당 페이지가 존재하는지 찾는 용도 → 존재하지 않는다면 바로 페이지폴트 발생
        - 이중연결리스트: 페이지 존재한다면 페이지 삽입/삭제/조회 진행
    1. NUR (Not Used Recently, Clock 알고리즘)
        - 최근에 **참조도 없고, 수정도 안 된 페이지**를 우선 교체
        - 하드웨어의 **R(Referenced), M(Modified)** 비트를 기반으로 4가지 분류:
            - (0,0), (0,1), (1,0), (1,1)
        - 시계방향으로 돌면서 Refereced=0을 찾고, 0인 페이지를 교체 후 해당 부분을 1로 바꿈
        - LRU를 **간단히 근사화**한 알고리즘
    2. LFU (Least Frequently Used)
        - **사용 횟수가 가장 적은 페이지**를 교체
        - 각 페이지마다 참조 횟수를 기록
        - 자주 쓰는 페이지는 오래 살아남음
    

### 프로세스

![image](https://github.com/user-attachments/assets/d1be85c4-5c45-44b9-8069-4d793ac11855)


### 프로세스와 컴파일 과정

1. 전처리: 소스코드 주석 제거. #include같은 헤더 파일 병합
2. 컴파일러: 오류 처리, 코드 최적화하여 어셈블리어로 변환
3. 어셈블러: 어셈블리어 → 목적 코드(object code)로 변환
4. 링커: 라이브러리 함수 + 다른 파일들 목적 코드를 결합하여 실행 파일 생성(확장자: .exe/.out)

### 프로세스 상태

<img width="705" alt="image" src="https://github.com/user-attachments/assets/f5283aa5-892f-4696-9807-06c42c768ca4" />


- 생성 상태 (New)
    - fork, exec 함수를 통해 생성
    - PCB 할당
    - fork(): 부모 프로세스 주소 공간 복사. 새로운 자식 프로세스 생성. 주소 공간만 복사하며 부모 프로세스의 비동기 작업을 상속하지 않음
    - exec(): 새롭게 프로세스를 생성하는 함수
- 준비 (Ready)
    - CPU로부터 자원을 할당받기 위해 기다리고 있는 상태
    - Ready queue에 들어있으나 아직 CPU를 할당받지 못 한 상태
- 대기 중단 상태 (Ready Suspended)
    - 메모리 부족으로 일시 중단된 상태
- 실행 (Run)
    - CPU 소유권과 메모리를 할당받고 실행 중인 상태
- 중단 (Blocked)
    - 인터럽트로 인해 프로세스가 차단된 상태
- 일시 중단 상태(Blocked Suspended)
    - 중단된 상태에서 프로세스가 재실행되려고 했으나, 메모리 부족으로 일시 중단된 상태
- 종료 (terminated)
    - 할당받은 메모리와 CPU를 해제한 상태

### 프로세스 메모리 구조

![image](https://github.com/user-attachments/assets/5455110b-0ac7-4186-88a3-131317051b30)


- 코드: CPU가 해석 가능한 기계어 형태로 저장되어 있는 프로그램 함수 코드
- 데이터: 코드가 실행될 때 사용되는 전역변수, 정적변수, 배열 등
    - .data: 전역변수, static/const 선언 & 0이 아닌 값으로 초기화된 데이터
    - .bss: 초기화되지 않은 데이터
- 스택: 임시 메모리 영역
    - 지역변수, 매개변수, 리턴값
    - 함수 호출시 할당, 함수 호출 완료시 소멸
- 힙: 동적으로 할당되는 데이터 저장 공간

### PCB(Process Control Block)

- 운영체제에서 프로세스에 대한 메타데이터를 저장한 자료구조
- 커널모드에서만 접근 가능

### 프로세스 컨텍스트 스위칭

- 발생조건: 한 프로세스에 할당된 단위 시간이 종료되거나 / 인터럽트가 발생했을 때
- CPU가 현재 실행 중인 프로세스 상태를 PCB에 저장 + 다음에 실행할 프로세스 상태(PCB) 복원
- 비용
    - 다음 사용할 프로세스를 위해 CPU 메모리 초기화 후 새로운 명령어와 데이터를 가져와야 함 → 유휴 시간 발생
    - 프로세스 전환시 TLB(물리↔논리주소 기록 테이블)도 초기화함으로 새 프로세스 주소 변환시 TLB 미스 발생
- 왜 발생하는가?
    - CPU는 한 번에 하나의 프로세스만 실행 가능 → CPU 사용 효율성을 높이기 위해
    - 특정 프로세스가 CPU 독점하는 것을 막고
    - Page Fault나 우선순위가 높은 프로세스가 생기면 그 프로세스를 우선 실행하기 위해 발생
    - 특정 시간(타임 슬라이스) 단위마다 운영체제의 스케줄링에 의해 일어남
- cf) 크롬은 탭마다 프로세스를 분리해서 사용함
    - 탭 하나가 죽는다고 다른 탭까지 죽으면 안되니까
    - 탭마다 주소공간을 완전히 분리해서 한 탭이 감염되도 다른 탭이 감염되지 않게 하기 위해

### 멀티프로세스 환경에서 프로세스 간 메모리 공유 방식(IPC)

1. 공유 메모리
    - 여러 프로세스에 접근 권한이 부여되어 있는 메모리
    - 장점
        - 오버헤드 적음: 통신 방식이 아닌 메모리 자체를 공유하는 방식이기 때문에 데이터 전달 필요 없음
    - 단점
        - 공유메모리임으로 동기화 필요
2. 파일
    - 디스크에 저장된 파일 / 서버에 저장된 데이터 활용
3. 소켓
    - TCP/UDP 활용하여 데이터 전송
4. 익명 파이프
    
    ![image](https://github.com/user-attachments/assets/8ee912c4-9057-4acb-bc3f-2875274fd1fc)
    
    - 프로세스 간 FIFO 방식으로 읽히는 임시 공간 파이프
    - 1:1 단방향 방식 → 한 프로세스는 쓰기만 가능. 다른 프로세스는 읽기만 가능
    - 부모-자식 프로세스 간에서만 사용 가능
5. 명명된 파이프
    
    ![image](https://github.com/user-attachments/assets/ba780e8f-e4f8-4b88-b805-6ae14d0817af)
    
    - 다중 프로세스 간 통신 & 서버-클라이언트 통신 구조를 만들어주는 파일 시스템에 특정 경로로 생성되는 특수 파일
    - 두 개 이상의 독립된 프로세스가 통신할 수 있음(부모-자식 관계일 필요 X)
    - 동일 컴퓨터의 여러 프로세스 / 다른 네트워크 상의 컴퓨터와도 통신 가능
6. 메시지 큐
    - 커널에서 전역적으로 관리되는 메시지 큐
    - 다중 프로세스 간 통신 가능
    - 여러 프로세스가 접근하므로 커널에서 전역으로 관리

### 스레드

- 프로세스가 할당받은 자원을 이용하는 **실행 흐름의 단위**
- 코드, 데이터, 힙 공간은 다른 스레드와 공유
- 스택은 스레드 고유의 공간 → 독립적인 함수 호출 가능 → 독립적인 실행 흐름을 가짐
- 단점: 하나 스레드 오류나면 같은 프로세스 내에 있는 스레드는 전부 오류남

### 멀티스레드

- 장점
    1. 효율성: 같은 프로세스 내에 위치한 스레드는 heap, data, code 영역을 공유하기 때문에 자원의 효율적인 활용이 가능함
    2. 컨텍스트 스위칭 오버헤드가 작다: 자원을 공유하기 때문에 stack 관련 정보만 교체하면 돼서 비용이 저렴함
- 단점
    1. 안정성 문제: 스레드 간 영향을 준다. 하나가 오류나면 전부 오류 발생임
    2. 동기화로 인한 성능 저하: 공유 자원에 대한 접근 때문에 병목 현상 발생 가능
- 예) 웹 브라우저의 렌더러 프로세스
    - 여러 스레드로 분리하여 작업을 병렬로 처리

### 스레드 컨텍스트 스위칭

- CPU 실행을 한 스레드 → 다른 스레드로 바꾸는 과정
- 한 프로세스 내부에서 하나의 스레드만 CPU를 사용할 수 있음(동시 불가)
    - 멀티코어라면 가능
    - 싱글코어라면 불가능 → 동시에 진행되는 거처럼 보이게 하기 위해 스레드 컨텍스트 스위칭이 필요
    - cf) 코어: CPU 내에서 연산을 진행하는 단위 → 코어 개수만큼 멀티프로세스/스레딩 가능
- 메모리 전환 과정이 없기 때문에 오버헤드가 프로세스 컨텍스트 스위칭에 비해 매우 작음

### 공유자원

- 시스템 내부에서 여러 프로세스, 스레드가 함꼐 접근할 수 있는 자원/변수
- race condition: 두 개 이상의 프로세스가 동시에 read/write하려는 상황
- critical section: 공유자원에 접근하는 순서에 따라 결과가 달라지는 코드 영역

### 뮤텍스 & 세마포어

- 언제 사용할까? 멀티스레드/프로세스 환경에서 공유 자원을 보호하기 위해 (임계 영역을 만들지 않기 위해)
- 공통점: 공유 자원에 대한 접근을 제어하는 동기화 도구
- 뮤텍스: 한 스레드만 critical section을 사용할 수 있게 하는 lock 객체
    - 락을 건 스레드만 잠금 해제할 수 있음
    - 다른 스레드는 대기해야 함
    - critical section 실행시간이 짧은 경우 비효율적
        - 대기 큐에 들어있는 스레드가 잠자고 깨는데(컨텍스트 스위칭) 시간이 상대적으로 더 크기 때문
- 세마포어: 동시에 접근할 수 있는 스레드 수를 정해주는 카운터 기반 동기화 객체
    - 동시에 n개까지 함께 접근 가능
    - 소유 개념 존재 X
    - 핵심 연산
        - `wait()` : 자원을 사용하려고 할 때 호출 → 세마포어 -= 1
        - `signal()` : 자원 사용을 마친 후 호출 → 세마포어 += 1
    - 바이너리 세마포어: 0/1만 가질 수 있는 세마포어
    - 카운팅 세마포어: 여러 값을 가질 수 있는 세마포어 → 여러 자원에 대한 접근을 제어할 수 있음

### Deadlock 데드락

- 발생 조건
    1. 상호배제: 한번에 프로세스 하나만 해당 자원을 사용할 수 있음. 사용 중인 자원을 사용하고 싶다면 자원이 해제될까지 기다려야 함
    2. 점유 대기: 자원을 최소한 하나 보유하고, 다른 자원을 점유하기 위해 대기하는 프로세스가 존재해야 함
    3. 비선점: 이미 할당된 자원을 강제로 뻇을 수 없음
    4. 순환 대기: 대기 프로세스가 순환 형태로 되어 있어야 함
    
    ⇒ 4가지 조건을 모두 만족해야 데드락이 발생함
    
- 해결 방법
    1. 데드락 조건을 만족시키지 않도록 설계
    2. 사이클 존재 여부 파악 후 관련 프로세스를 삭제
    3. Banker’s Algorithm
        - 요청을 받았을 때, 그 요청을 수락해도 안전한지 미리 검사 후 할당
        - 실제 운영체제에서 사용하기에는 비용이 크기 때문에 이론적으로만 가능

### CPU 스케줄링

- CPU를 사용하려고 하는 프로세스 사이의 우선 순위를 관리하는 일
- 비선점형 알고리즘: 중간에 뺏어갈 수 없는 방식
    1. FCFS: 먼저 요청들어온 것을 먼저 실행 → 병목현상 발생 가능
    2. SJF: 실행시간이 가장 짧은 것을 먼저 실행
        - 문제점
            1. 실행시간이 긴 작업이 영원히 자원을 할당받을 수 없음(기아현상 = starvation)
            2. 정확한 실행시간을 예측하기 어려움
        - 대안
            1.  HRN (Highest response-ratio next)
                - 비선점형
                - 실행시간이 긴 프로세스가 SJF에 불리하기 때문에 대기시간 + 실행시간을 함께 사용
                - 기다리는 시간에 비례하여 우선순위를 부여하여 무한 연기 문제를 방지하는 기법 = Aging 기법
            2. SRTF (shortest remaining time first)
                - 선점형 기법
                - 더 짧은 작업이 들어오면 현재 작업이 중단됨
- 선점형 알고리즘: 다른 프로세스가 중간에 소유권을 뺏어갈 수 있음
    1. Round Robin: 단위 시간동안만 CPU를 할당하고, 그 시간 안에 끝나지 않으면 다시 Ready Queue 뒤로 이동
        - 현대 CPU 스케줄러가 Round Robin을 쓰는 이유는?
            - 공정성과 반응성을 중요시하기 대문
            - 평균 응답 시간이 줄어듦
            - 로드밸런서 역할도 가능
    2. SRTF: SJF 기반이나 더 짧은 작업이 들어오면 현재 프로세스를 중지하고 해당 프로세스를 수행

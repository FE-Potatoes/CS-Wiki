# 3. 운영체제

### 3.1.1 운영체제의 역할과 구조

- 운영체제의 역할
  1. CPU 스케줄링과 프로세스 관리: CPU 소윺권을 어떤 프로세스에 할당할지, 프로세의 생성과 삭제, 자원 할당 및 반환을 관리
  2. 메모리 관리: 한정된 메모리를 어떤 프로세스에 얼만큼 할당해야 하는지 관리
  3. 디스크 파일 관리: 디스크 파일을 어떠한 방법으로 보관할지 관리
  4. I/O 디바이스 관리: 마우스, 키보드와 컴퓨터 간에 데이터를 주고받는 것을 관리

- 운영체제 구조
  - 유저 프로그램
  - 인터페이스(GUI, CUI)
  - 시스템콜
  - 커널
  - 하드웨어

-> 이 중 인터페이스 ~ 커널까지가 운영체제

시스템콜: 운영체제가 커널에 접근하기 위한 인터페이스이며 유저 프로그램이 운영체제의 서비스를 받기 위해 커널 함수를 호출할 때 사용

```
[ 사용자 프로그램 ]
        ↓ (시스템 콜)
[ 운영체제 커널 ]
        ↓
[ 하드웨어 제어 (CPU, 메모리, 디스크 등) ]
```

- 사용자 프로그램은 직접 하드웨어 접근 불가
- 대신 시스템 콜을 통해 커널에 요청
- 커널이 요청을 수행하고, OS가 자원 관리

<br/>

- modebit란?
  - CPU가 현재 어떤 모드에서 실행 중인지 나타내는 1비트 플래그
  - 이 비트는 User Mode(사용자 모드)와 Kernel Mode(커널 모드)를 구분
  - 보안과 안정성을 위해 필수적인 개념

| 모드              | 설명             | 접근 권한                     |
| --------------- | -------------- | ------------------------- |
| **User Mode**   | 일반 애플리케이션 실행 시 | 제한된 명령어, 직접적인 하드웨어 접근 불가  |
| **Kernel Mode** | OS 커널 코드 실행 시  | 전체 명령어 실행 가능, 모든 자원 접근 가능 |

- CPU 연산 처리
  1. 제어장치가 메모리에 계산할 값을 로드, 동일하게 레지스터에도 로드
  2. 제어장치가 레지스터에 있는 값을 계산하라고 산술논리 연산 장치에 명령
  3. 제어장치가 계산된 값을 다시 레제스터에서 메모리로 저장

- 산술논리연산장치란?
  - 덧셈, 뺄셈 같은 두 숫자의 산술 연산자와 논리합, 논리곱 같은 연산을 계산하는 디지털 회로 장치

- 인터럽트란?
  - 어떤 신호가 들어왔을 때 CPU를 잠깐 정지시키는 것을 의미
  - 키보드, 마우스 등을 통한 인터럽트, 프로세스 오류 등 존재
  - 인터럽트에는 우선순위가 존재하고 종류가 존재함

- 하드웨어 인터럽트란?
  - 키보드를 연결한다거나 마우스를 연결하는 일 등의 IO 디바이스에서 발생하는 인터럽트
- 소프트웨어 인터럽트
  - 프로세스 오류 등을 통해 프로세스가 시스템콜을 호출할 때 발생

- DMA 컨트롤러란?
  - I/O 디바이스가 메모리에 직접 접근할 수 있도록 하는 하드웨어 장치
  - CPU에만 너무 많은 인터럽트 요청이 들어오기 때문에 CPU 부하를 막아줌
  - CPU 일을 부담하는 보조 일꾼의 역할

- 메모리란?
  - 컴퓨터가 실행 중인 프로그램, 데이터, 명령어 등을 일시적으로 저장하고 CPU가 빠르게 접근할 수 있게 해주는 저장 장치
  - CPU는 계산을 담당하고, 메모리는 기억을 담당
  - 메모리가 크면 동시에 많은 일을 처리 가능

- 타이머란?
  - 몇 초 안에 작업이 끝나야 하는 시간. 프로그램이 작동할 때 제한을 걸기 위해 존재

- 디바이스 컨트롤러란?
  - CPU는 다양한 I/O 장치 (예: 프린터, 키보드, 디스크)를 직접 제어하기 어려움. 각 장치마다 작동 방식이 다르기 때문에 전용 컨트롤러가 필요. 디바이스 컨트롤러가 장치와 통신하고, 그 결과만 CPU에 전달

## 3.2 메모리

### 3.2.1 메모리 계층

1. 레지스터: CPU 안에 있는 작은 메모리, 휘발성, 속도 가장 빠름, 기억 용량이 가장 적음
2. 캐시(L1, L2): 휘발성, 속도 빠름, 기억 용량 적음.
3. 주기억장치: RAM을 가리킴. 휘발성, 속도 보통, 기억 용량이 보통
4. 보조기억장치: HDD, SDD 비휘발성, 속도 낮음, 기억 용량 많음

- 캐시란?
  - CPU는 매우 빠르다.
  - RAM은 상대적으로 느리다.
  - 둘 사이의 속도 차이 때문에 CPU가 RAM을 기다리는 시간이 생기면 성능 낭비
  - 캐시는 이 속도차를 메꾸는 중간 계층으로 성능 최적화에 필수

- 지역성의 원리
  - 프로그램은 메모리의 특정 부분을 집중적으로 반복해서 참조한다는 경향이 있음. 이 성질을 이용하면, 자주 참조되는 데이터를 미리 빠른 메모리에 올려둘 수 있음 → 바로 캐시의 핵심 아이디어

- 시간적 지역성
  - 최근에 접근한 데이터는 곧 다시 접근될 가능성이 높다
  - 예: 반복문 안의 변수, 함수의 결과 재사용

```javascript
for (let i = 0; i < 10000; i++) {
  sum += arr[i];  // arr[i] → 반복적으로 참조됨
}
```

- 공간적 지역성
  - 접근한 주소 근처의 데이터도 곧 사용할 가능성이 높다
  - 예: 배열을 순차적으로 접근할 때

```javascript
for (let i = 0; i < 10000; i++) {
  sum += arr[i];  // arr[i+1], arr[i+2]도 곧 접근
}
```

-> 캐시는 이 성질을 이용해서 현재 접근한 데이터뿐 아니라 근처 데이터까지 한꺼번에 불러와 저장함 (이걸 캐시 라인이라고 함)

- 캐시 히트
  - CPU가 요청한 데이터가 이미 캐시에 존재함
  - 즉시 데이터를 읽을 수 있으므로 빠름
  - CPU -> 캐시 확인 -> 있음! -> 바로 처리

- 캐시 미스
  - CPU가 요청한 데이터가 캐시에 없음
  - 결국 RAM(느린 메모리)에서 가져와야 함. 느림
  - 가져온 후에는 캐시에 저장하여 다음 접근 시 캐시 히트 가능
  - CPU -> 캐시 확인 -> 없음 -> RAM 접근 -> 캐시에 복사 -> 처리

- 캐시 매핑
  - 메인 메모리의 데이터 블록을 캐시의 어느 위치에 저장할지 결정하는 방식
  - 캐시는 크기가 작기 때문에, 메모리 전체 데이터를 모두 담을 수 없음
  - 그래서 일부만 담아야 하고, 어디에 담을지 정해줘야함
  - 아래 3가지 방식

| 매핑 방식                            | 설명                                            | 장점         | 단점                          |
| -------------------------------- | --------------------------------------------- | ---------- | --------------------------- |
| **직접 매핑**       | 하나의 메모리 블록은 **특정 캐시 라인 하나에만 저장**됨             | 구현이 단순, 빠름 | 충돌 발생 가능성 큼  |
| **연관 매핑**  | 메모리 블록은 **캐시 어디든 저장 가능**                      | 충돌 없음      | 구현 복잡, 비용 높음                |
| **집합 연관 매핑**    | 캐시를 여러 집합으로 나누고, 각 집합 안에서만 저장 가능 | 균형 잡힌 방식   | 구현 복잡도 중간                   |

- 웹 브라우저 캐시
  - 쿠키
  - 로컬 스토리지
  - 세션 스토리지

- 데이터베이스의 캐싱 계층 
  - 레디스

### 3.2.2 메모리 관리

- 가상 메모리란?
  - 가상 메모리는 운영체제가 물리적인 메모리의 크기를 넘어서는 메모리 공간을 제공하기 위해 사용하는 기술입니다. 이 개념은 프로그램이 실제 메모리 보다 더 많은 메모리를 사용할 수 있게 하며, 메모리 관리와 보호, 효율성 향상을 도와줍니다.
  프로그램은 메모리를 가상 주소로 접근합니다. 운영체제는 이 가상 주소를 실제 메모리의 물리 주소로 매핑합니다. 주소를 매핑하는 정보가 들어 있는 곳은 페이지 테이블이라고 합니다.

- 스와핑이란?
  - 운영체제가 프로세스 전체 또는 메모리 페이지 일부를 디스크로 옮기는 작업을 말합니다. 이는 물리 메모리의 공간이 부족할 때, 메모리를 효율적으로 사용하기 위한 방법
  - 물리 메모리가 가득 찼을 때, 어떤 페이지가 오랫동안 사용되지 않았을 때, 새로운 프로세스가 실행되거나, 기존 프로세스가 더 많은 메모리를 요구할 때 사용됨

- 페이지 폴트이란?
  - 주소 공간에는 존재하지만 지금 컴퓨터의 RAM에는 없는 데이터에 접근했을 경우 발생
  1. 명령어를 통한 접근. 주소 공간에는 존재하지만 이 컴퓨터 RAM에 없는 데이터
  2. 운영체제는 실제 디스크로부터 사용하지 않는 프레임을 찾음
  3. 스와핑 발생 (페이지 교체 알고리즘)
  4. 스와핑 후 다시 명령어 시작

- 스레싱이란?
  - 메모리에 너무 많은 프로세스가 동시에 올라가면 스와핑이 많이 일어나서 발생하는 것
  - 해결방법으로는 메모리를 늘리거나, HDD -> SSD로 변경 방법, 작업 세트와 PFF

- 작업 세트란?
  - 작업 세트란, 어떤 시간 간격 동안 한 프로세스가 실제로 자주 사용하는 페이지들의 집합을 의미합니다. 즉, 어떤 프로세스가 실행되면서 일정 시간 동안 접근하는 페이지들을 묶은 실제 필요한 메모리 공간

- PFF란?
  - 페이지 폴트 빈도를 조절하는 방법으로 상한선과 하한선을 만드는 방법

- 메모리 할당
  - 연속 할당
    - 메모리에 연속적으로 공간을 할당하는 것
  - 고정 분할 방식
    - 단순한 메모리 관리: 분할이 고정되어 있어 관리가 용이합니다.
    - 내부 단편화 발생: 프로세스 크기가 분할 크기보다 작을 경우, 남는 공간이 낭비됩니다.
    - 프로세스 크기 제한: 프로세스가 분할 크기보다 클 경우, 할당이 불가능합니다.
  - 가변 분할 방식
    - 효율적인 메모리 사용: 프로세스 크기에 맞게 메모리를 할당하여 내부 단편화를 줄입니다.

- 최초 적합
  - 동작 방식: 메모리의 빈 공간을 순차적으로 검색하여, 요청된 크기를 수용할 수 있는 첫 번째 빈 공간에 프로세스를 배치
  - 검색을 최소화하여 빠른 할당이 가능
  - 외부 단편화가 발생할 수 있습니다. 공간이 낭비될 수 있습니다

- 최적적합
  - 동작 방식: 모든 빈 공간을 검색하여, 요청된 크기를 수용할 수 있는 가장 작은 빈 공간에 프로세스를 배치
  - 외부 단편화를 최소화할 수 있음
  - 모든 빈 공간을 검색해야 하므로 할당 시간이 길어질 수 있음
  - 작은 조각의 빈 공간이 많이 남아 외부 단편화가 발생할 수 있음

- 최악적합
  - 프로세스와 크기와 가장 차이 많은 것에 할당

- 불연속 할당
  - 메모리를 연속적으로 할당하지 않는 방법은 페이징, 세그멘테이션, 페이지드 세그멘테이션 기법 존재

- 페이징
  - 동일한 크기의 페이지 단위로 나누어 메모리의 서로 다른 위치에 프로세스를 할당
  - 외부 단편화 없음
  - 내부 단편화 가능성 있음

- 세그멘테이션
  - 페이지 단위가 아닌 세그먼트 단위로 나누는 방식
  - 필요한 크기만큼 메모리를 할당하므로 내부 단편화가 발생하지 않음


- 페이지드 세그멘테이션
  - 페이지드 세그멘테이션은 페이징과 세그멘테이션의 장점을 결합한 방식으로, 프로세스를 세그먼트로 나눈 후, 각 세그먼트를 다시 고정 크기의 페이지로 분할하여 관리

- 페이지 교체 알고리즘
  - 메모리는 한정되어 있기 때문에 스와핑이 많이 일어남. 스와핑이 많이 일어나지 않게 설계해야 되며 이것은 페이지 교체 알고리즘을 통해 스와핑 발생
  - 오프라인 알고리즘
    - 미래에 참조되는 페이지와 현재 할당하는 페이지를 바꾸는 방법, 가장 좋은 방법이지만 미래에 사용되는 프로세스를 알 수 있는 방법이 없음
  - FIFO: 가장 먼저 온 페이지를 교체 영역에 가장 먼저 놓는 방법
  - LRU: 가장 오래된 페이지를 변경하는 방법
  - LFU: 가장 참조 횟수가 작은 페이지 교체 방법

## 3.3 프로세스와 쓰레드

- 프로그렘이 메모리에 올라가면 인스턴스화 되고, 이후 운영체제의 CPU 스케줄러에 따라 CPU 프로세스를 실행

### 3.1.1 프로세스와 컴파일 과정

- 프로세스는 HDD/SDD에 저장된 프로그램이 두번 클릭하면 메모리에 올라가 인스턴스화 된 것을 의미

1. 전처리
  - 소스 코드에서 컴파일 전에 수행해야 할 작업을 처리
  - 주석 제거
  - 헤더 파일 포함 처리 (#include)
  - 매크로 치환 (#define)
  - 전처리된 소스 코드 파일 (.i 확장자) 생성
2. 컴파일러: 오류처리, 코드 최적화 작업을 하며 어셈블리어로 변환
3. 어셈블러: 목적코드로 변환하고 목적파일 생성
4. 링커: 목적파일을 다른 파일들과 결합해 실행 파일 생성 ex) .exe, .out 확장자

### 3.3.2 프로세스 상태

1. 생성: 프로세스가 생성되어 초기화되는 단계. 운영체제가 프로세스 제어 블록(PCB)을 생성하고 필요한 자원을 할당

2. 준비: 프로세스가 실행을 위해 CPU 할당을 기다리는 상태.Ready Queue에 들어가며, CPU 스케줄러에 의해 선택되기를 대기

3. 실행: 프로세스가 CPU를 할당받아 명령어를 실행하는 상태. 실제 작업이 수행되며, 할당된 시간 동안 CPU를 사용

4. 대기: 프로세스가 입출력(I/O) 등의 이벤트를 기다리는 상태. 필요한 이벤트가 발생하면 다시 준비 상태로 전환

5. 종료: 프로세스의 실행이 완료되어 시스템에서 제거되는 상태. 할당된 자원이 해제되고, PCB가 삭제됩니다.

- 프로세스 상태 전이
  - 생성 → 준비: 운영체제가 프로세스를 초기화하고 준비 큐에 삽입합니다.
  - 준비 → 실행: CPU 스케줄러가 준비 상태의 프로세스를 선택하여 CPU를 할당합니다.
  - 실행 → 대기: 프로세스가 I/O 요청 등으로 인해 대기 상태로 전환됩니다.
  - 실행 → 준비: 할당된 시간이 만료되거나, 더 높은 우선순위의 프로세스가 등장하여 준비 상태로 전환됩니다.
  - 대기 → 준비: 대기 중인 이벤트가 완료되면 준비 상태로 전환됩니다.
  - 실행 → 종료: 프로세스의 작업이 완료되어 종료 상태로 전환됩니다.

### 3.3.3 프로세스와 메모리 구조

- 스택, 힙, 데이터 영역, 코드 영역으로 나뉨
- 자바스크립트에서는 원시값과 실행 컨텍스트는 콜 스택에 저장되며, 참조형 데이터는 메모리 힙에 저장

### 3.3.5 멀티프로세싱

- 동시에 두 가지 이상의 일을 수행하는 것을 의미
- 병렬처리가 가능하며 특정 이슈가 발생하더라도 다른 프로세스를 이용해 처리 가능

- 웹 브라우저: 멀티프로세스 구조
  - 브라우저 프로세스: 주소 표시줄, 북마크, 뒤로 앞으로 가기 버튼 담당, 네트워크 요청 또는 파일 접근 권한 담당
  - 렌더 프로세스: UI 부분의 모든 것을 제어
  - 플러그인 프로세스: 플러그인 제어 담당
  - GPU 프로세스: 화면을 그리는 부분을 제어

- IPC란?
  - 여러 프로세스가 데이터를 교환하고 협력할 수 있도록 지원하는 메커니즘
  - 다양한 IPC 방식이 존재

- 공유 메모리
  - 여러 프로세스가 동일한 메모리 영역을 공유하여 데이터를 교환하는 방식
  - 가장 빠른 IPC 방식 중 하나로, 대용량 데이터 전송에 효율적
  - 동기화 문제를 해결하기 위해 동기화 기법이 필요

- 파일
  - 디스크에 저장된 데이터

- 소켓
  - 네트워크를 통해 서로 다른 시스템 또는 동일 시스템 내의 프로세스 간에 통신하는 방식
  - TCP/UDP 존재

- 익명 파이프
  - FIFO방식으로 부모-자식 프로세스 간에 단방향으로 데이터를 전달하는 파이프 방식

- 명명된 파이프
  - 파일 시스템에 이름을 가진 파이프로, 서로 관계없는 프로세스 간에도 통신이 가능
  - 단방향 또는 양방향 통신이 가능

- 메세지 큐
  - 운영체제가 관리하는 메시지 큐를 통해 프로세스 간에 메시지를 주고받는 방식
  - 직관적이고 간단하다는 장점 존재

### 3.3.6 쓰레드와 멀티스레딩

- 쓰레드
  - 프로세스의 실행 가능한 가장 작은단위
  - 프로세스는 여러 쓰레드를 가질 수 있음
  - 개별적으로 생성되는 프로세스와 달리 쓰레드는 코드, 데이터, 힙은 쓰레드끼리 공유함

- 멀티 쓰레딩
  - 나의 프로세스 내에서 여러 개의 **스레드(Thread)**를 생성하여 동시에 여러 작업을 수행할 수 있도록 하는 프로그래밍 기법
  - 병렬 작업을 통해 실행 시간 단축
  - 공유 자원에 대한 접근을 적절히 관리하지 않으면, 경쟁 상태(Race Condition)가 발생
  - 스레드 간 전환에는 오버헤드가 발생하며, 과도한 스레드 생성은 오히려 성능 저하

### 3.3.7 공유 자원과 임계 영역

- 공유 자원
  - 시스템 안에서 각 프로세스, 스레드가 접근할 수 있는 자원
  - 모니터, 프린터, 메모리, 파일, 데이터 등

- 경쟁 상태
  - 경쟁 상태란 두 개 이상의 프로세스나 스레드가 동일한 공유 자원에 동시에 접근하려고 할 때, 그 실행 결과가 접근 순서나 타이밍에 따라 달라지는 상황을 말합니다. 이로 인해 프로그램의 동작이 예측 불가능해지고, 오류나 버그가 발생

- 임계 영역
  - 둘 이상의 프로세스, 쓰레드가 공유 자원에 접근할 때 선수 등의 이유로 결과가 달라지는 코드의 영역
  - 해결 방법은으로 뮤텍스, 세마포어, 모니터 세 가지 존재
  - 상홉 배제, 한정 대기, 융통성 특징 존재

### 3.3.8 교착 상태

- 두 개 이상의 프로세스들이 서로가 가진 자원을 기다리며 중단된 상태.
- 교착 상태의 원인
  - 상호 배제: 한 프로세스가 자원을 독점. 다른 프로세스들이 접근 불가
  - 점유 대기: 특정 프로세스가 점유한 자원들 다른 프로세스가 요청
  - 비선점: 다른 프로세스의 자원을 강제로 가져오지 못함
  - 환형 대기: 동시에 서로의 자원을 요청

## 3.4 CPU 스케줄링 알고리즘

- CPU 스케줄러는 CPU 스케줄링 알고리즘에 따라 프로세스에서 해야 하는 일을 쓰레드 단위로 CPU에 할당함
- 프로그램이 실행될 떄는 CPU 스케줄링이 어떤 프로그램에 CPU 소유권을 줄 것인지 결정

### 3.4.1 비선점형 방식

- 프로세스가 스스로 CPU 소유권을 포기하는 방식
- 강제로 프로세스를 중지하지 않음
- 컨텍스트 스위칭으로 인한 부하가 적음

- FCFS
  - 가장 먼저 온 것을 먼저 처리하는 알고리즘 (FIFO)
  - 길게 수행되는 프로세스 때문에 준비 큐에서 오래 기다리는 현상이 발생하는 단점

- SJF
  - 실생 시간이 짧은 프로세스를 가장 먼저 실행하는 알고리즘
  - 긴 시간을 가진 프로세스가 실행되는 않는 현상이 일어나며 평균 대기 시간이 짧음
  - 하지만 실제로 실행 시간을 알 수 없기 때문에 과거의 실행했던 시간을 토대로 추측

- 우선순위
  - 기존 SJF 스케줄링의 경우 긴 시간을 가진 프로세스가 실행되지 않은 단점이 있음
  - 이 단점을 보안하기 위해 '우선 순위를 높이는 방법(aging)'을 사용해 보완한 알고리즘
  - SJF에 국한되지 않음

### 3.4.2 선점형 방식

- 지금 사용하고 있는 프로세스를 알고리즘에 의해 중단하고 강제로 다른 프로세스에 CPU 소유권을 할당하는 방식

<br/>

- 라운드 로빈
  - 현대 컴퓨터가 사용하는 선점형 알고리즘 스케줄링 방법
  - 각 프로세스는 동일한 할당 시간을 주고 그 시간 안에 끝나지 않으면 다시 준비 큐의 뒤로 가는 알고리즘

- SRF
  - SJF는 중간에 실행 시간이 더 짧은 작업이 들어와도 기존 것을 마치고 그 다음 짧은 작업을 이어나감
  - 하지만 SRF는 더 짧은 작업이 들어오면 수행하던 프로세스를 중단하고 해당 프로세스를 수행

- 다단계 큐
  - 우선순위에 따른 준비 큐 여러 개 사용
  - 큐마다 라운드 로빈이나 FCFS 등 다른 스케줄링 알고리즘 적용
  - 큐 간의 프로세스 이동이 안 되기에 스케줄링 부담은 적지만 유연성이 떨어지는 단점 존재
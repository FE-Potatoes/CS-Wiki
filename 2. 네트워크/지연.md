# 지연

## 네트워크 기초

네트워크

- 노드와 링크가 서로 연결되어 있으며 리소스를 공유하는 집합
- 많은 트래픽을 처리할 수 있으며, 지연 시간이 짧고 장애 빈도가 적으며 좋은 보안을 갖춰야 함

네트워크 토폴로지

- 노드와 링크가 어떻게 배치되어 있는지에 대한 방식이자 연결 형태
- 종류
  - 트리 토폴로지 : 계층형 / 노드의 추가, 삭제가 쉽고 하위 노드에 영향
  - 버스 토폴로지 : 중앙 통신 회선 하나에 여러 개의 노드가 연결되어 공유하는 네트워크 구성, 근거리 통신망에서 사용, 스푸핑(스위칭 기능을 마비시켜 패킷이 악의적인 수신부로 전달됨) 가능 문제
  - 스타 토폴로지 : 중앙 노드에 모두 연결된 네트워크 구성, 노드 추가, 에러 탐지가 쉬움, 패킷의 충돌 발생 가능성이 적음, 중앙 노드 문제 발생 시 전체 네트워크 마비 및 고가의 설치 비용 존재
  - 링형 토폴로지 : 각 노드가 양 옆의 두 노드와 연결되며 연속된 길을 통해 통신하는 망 구성 방식, 노드에서 노드로 데이터가 이동, 네트워크 구성 변경이 어렵고 회선 장애 시 전체 네트워크에 영향
  - 메시 토폴로지 : 그물망처럼 연결된 구조, 한 단말 장치에도 여러 개의 경로가 존재하므로 네트워크 문제 발생 시에도 트래픽 분산 처리 가능, 노드 추가가 어렵고 고가의 설치 비용 존재
- 전체 시스템의 성능이나 용량이 하나의 구성 요소로 인해 제한 받는 현상인 ‘병목 현상’을 올바르게 처리하기 위해 토폴로지가 활용됨

네트워크 분류

- LAN : 근거리 통신망, 전송 속도가 빠르고 혼잡하지 않음
- MAN : 대도시 지역 네트워크, 전송 속도 평균이며 LAN보다 혼잡
- WAN : 광역 네트워크, 전송 속도는 낮으며 MAN보다 혼잡

네트워크 성능 분석

- 네트워크 병목 현상의 주된 원인 : 네트워크 대역폭, 네트워크 토폴로지, 서버 CPU, 메모리 사용량, 비효율적 네트워크 구성
- Ping : 네트워크 상태를 확인하기 위해 대상 노드를 향해 일정 크기의 패킷을 전송하는 명령어, 해당 노드의 패킷 수신 상태와 연결 여부 확인 가능
- netstat : 접속된 서비스들의 네트워크 상태를 표시하는데 사용
- nslookup : DNS에 관련된 내용을 확인하기 위해 쓰는 명령어, 매핑된 IP를 확인하기 위해 사용
- tracert : 목적지 노드까지 네트워크 경로를 확인할 때 사용하는 명령어, 어느 구간에서 응답 시간이 느려지는지 알 수 있음

## TCP/IP 4계층 모델

Transmission Control Protocol, Internet Protocol
네트워크 에서 사용되는 통신 프로토콜의 집합

총 4개의 계층을 가지며, 애플리케이션 계층 / 전송 계층 / 인터넷 계층 / 링크 계층 으로 구성

- 애플리케이션 계층
  - FTP(장치와 장치 간 파일 전송에 사용되는 프로토콜), HTTP(웹 사이트를 이용하는 데 쓰이는 프로토콜), SSH(암호화 네트워크 프로토콜), SMTP(전자 메일 전송을 위한 통신 프로토콜), DNS(도메인 이름과 IP 주소 매핑) 등 응용 프로그램이 사용되는 프로토콜 계층
  - 웹 서비스, 이메일 등 서비스가 제공되는 계층
- 전송 계층
  - 송신자와 수신자를 연결하는 통신 서비스를 제공
  - 애플리케이션 계층과 인터넷 계층 사이의 데이터가 전달될 때 중계 역할을 함
  - TCP
    - 패킷 사이 순서를 보장, 수신 여부 확인, 가상회선 패킷 교환 방식 사용
  - UDP
    - 순서 보장x, 수신 여부 확인x, 데이터그램 패킷 교환 방식 사용
  - TCP 연결 성립 과정에서 ‘**3-way handshake**’ 작업 진행 => ‘신뢰성 구축’
    - SYN 단계 : ISN(Initial Sequence Number) 를 담아 클라이언트 -> 서버 전달
    - SYN - ACK 단계 : 서버가 SYN을 수신해 서버의 ISN을 보내며 승인번호로 ISN + 1를 클라이언트로 전달
    - ACK 단계 : 클라이언트는 ISN + 1 승인번호를 담아 서버에 전달
  - TCP 연결 해제 가정에서 ‘**4-way handshake**’ 작업 진행
    - 1단계 : 클라이언트가 FIN으로 설정된 세그먼트를 서버로 전달, 클라이언트는 FIN_WAIT_1
    - 2단계 : 서버는 ACK 승인 세그먼트를 클라이언트로 전달, 서버는 CLOSE_WAIT / 클라이언트는 ACK를 받으면 FIN_WAIT_2
    - 3단계 : 서버는 ACK 전달 뒤 일정 시간 이후 FIN 세그먼트를 클라이언트로 전달
    - 4단계 : 클라이언트는 TIME_WAIT 상태에서 ACK를 서버로 전달하면 서버는 CLOSED 상태, 이후 클라이언트도 일정 시간 대기 후 연결 해제
    - ** TIME_WAIT 은 지연 패킷으로 인한 무결성 문제, 장치간 연결이 올바르게 닫혔는지 확인하기 위해 대기 시간이 필요하기에 사용 **
- 인터넷 계층
  - 장치로부터 받은 네트워크 패킷을 IP 주소로 지정된 목적지로 전송하기 위해 사용되는 계층
  - 주소를 지정해 데이터를 전달하며, IP, ARP, ICMP 등이 있음
  - 비연결형적인 특징으로 전달이 올바른지에 대해 보장하지 않음
- 링크 계층
  - 실질적으로 데이터를 전달하며 장치 간 신호를 주고 받는 규칙을 정하는 계층
  - 네트워크 접근 계층, 2가지로 나뉘기도 함
  - (1) 물리 계층 : 무선 LAN과 유선 LAN을 통해 0과 1로 이루어진 데이터를 보내는 계층
  - (2) 데이터 링크 계층 : 이더넷 프레임을 통해 에러 확인, 흐름 제어, 접근 제어를 담당하는 계층

계층 간 데이터 송수신 과정

- HTTP를 통해 웹 서버에 있는 데이터를 요청하는 경우?
  - 애플리케이션 -> 전송 계층 : 요청 값이 캡슐화(상위 계층의 헤더와 데이터를 하위의 데이터 부분에 포함 + 헤더 삽입) 과정을 거쳐 전달
  - 링크 계층 : 서버와 통신
  - 해당 웹 서버의 링크 계층 -> 애플리케이션 계층까지 비캡슐화 과정을 거쳐 데이터 전송

PDU
Protocol Data Unit
네트워크의 계층에서 계층으로 데이터가 전달될 때의 단위

- 애플리케이션 계층 : 메시지
- 전송 계층 : 세그먼트 (TCP), 데이터그램 (UDP)
- 인터넷 계층 : 패킷
- 링크 계층 : 프레임(데이터 링크 계층), 비트(물리 계층)

### 네트워크 기기

계층별로 처리 범위를 나눌 수 있으며, 상위 계층 -> 하위 계층 처리 가능하지만 반대는 불가

- 애플리케이션 계층 : L7 스위치(로드 밸런서, 서버의 부하를 분산해 요청을 여러 서버로 나눠 트래픽 증가를 목표로 함)
- 인터넷 계층 : 라우터, L3 스위치
- 데이터 링크 계층 : L2 스위치, 브리지
- 물리 계층 : NIC, 리피터, AP

## IP 주소

ARP (Address Resolution Protocol)

- IP 주소로부터 MAC 주소를 구하는 IP와 MAC 주소의 다리 역할을 하는 프로토콜
- 가상 주소(IP)를 실제 주소(MAC)으로 변환
- RARP을 통해 그 반대로 변환

컴퓨터 간 통신은 IP주소 -> ARP주소 -> MAC주소 기반 통신으로 이루어짐

- 브로드캐스트 방식으로 송신 호스트가 연결된 모든 호스트에 ARP Request 전송
- 유니캐스트 방식으로 해당되는 호스트가 ARP Request 송신 호스트(고유 주소)로 데이터 전송

홉바이홉 통신

- 각 라우터는 패킷의 목적이 IP 주소를 기반으로 라우팅 테이블 조회 ->
  구간마다 패킷을 전달해나가며 최종 목적지에 도달하는 방식
  - 내 컴퓨터는 목적지 IP가 **내 서브네트워크 밖**이면 → **라우팅 테이블 확인**
  - 라우팅 테이블에 없으면 → **기본 게이트웨이로 전송**
  - 게이트웨이는 자신의 라우팅 테이블로 다음 경로 판단 → **다음 라우터로 패킷 전달**
  - 이후 각 라우터들은 **홉마다 라우팅 테이블을 보고** 다음 라우터로 계속 넘김
  - **최종 목적지**에 도착하면 응답도 **역방향으로 홉바이홉으로 돌아옴**

IP 주소 체계
IP 프로토콜은 IP 주소를 사용해 호스트나 네트워크 장비 식별
-> 인터넷에 접속한 컴퓨터와 라우터에 고유한 IP 주소를 할당

IPv4

- 32비트를 8비트 단위로 점을 찍어 표기
- 할당할 수 있는 IP주소의 개수 = 2^32 = 약 43억 개

IPv6

- 64비트를 16비트 단위로 점을 찍어 표기
- 할당할 수 있는 IP주소의 개수 = 2^128 = 약 340간 개

클래스 기반 할당 방식
IP주소를 8비트씩 나눈 그룹을 조합해 앞 부분을 네트워크 주소, 뒷 부분을 호스트 주소로 활용
네트워크 관리자가 각 장치에 대해 IP주소를 수동으로 할당
주소 낭비/부족 문제로 인해 효율성이 떨어짐

DHCP (Dynamic Host Configuration Protocol)
네트워크 상에서 장치들이 자동으로 IP주소를 할당받고, 네트워크 설정을 관리할 수 있도록 도와주는 프로토콜
DHCP 서버가 IP주소 풀을 관리하고, 사용가능한 주소를 동적으로 할당하게 됨

NAT (Network Address Translation)
패킷이 라우팅 장치를 통해 전송되는 동안 패킷의 IP주소 정보를 수정해 IP주소를 다른 주소로 매핑하는 방법
사설 IP주소, 공인 IP주소로 나눠 처리해 IP주소의 주소 부족 문제를 해결할 수 있음
여러 대의 호스트가 하나의 공인 IP주소를 사용해 인터넷에 접속하기 위해 사용됨

NAT 장점

- IP주소 절약
- 내부 네트워크의 IP주소가 드러나지 않기 때문에 보안이 강화됨

NAT 단점

- 하나의 공인 IP주소를 활용하기 때문에 어떤 내부 장치가 어떤 트래픽을 생성했는지 추적이 어려움
- 동시 접속으로 인해 접속 속도에 영향을 줄 수 있음

## HTTP

애플리케이션 계층에 속하며, 웹 서비스 통신에 사용

RTT (Round-Trip Time)
클라이언트가 서버로 패킷(요청)을 보내고 그에 대한 응답이 다시 클라이언트로 도달하기까지 걸리는 시간
Request -> Response 까지의 시간

RTT가 중요한 이유

- 인터넷의 속도를 결정하는 요소로, RTT값이 클수록 페이지 로딩이 느림
- 거리, 네트워크 품질, 라우터 수에 영향을 받음

HTTP/1.0
한 연결당 하나의 요청을 처리하도록 설계 -> RTT 증가
이미지 스플리팅, 코드 압축, 이미지 Base64 인코딩 방식으로 RTT 증가를 해결하고자 함

HTTP/1.1
매번 TCP 연결을 새롭게 하는 HTTP/1.0과 달리 한 번 TCP 초기화한 후, keep-alive 옵션을 표준화해 연결을 끊지 않고 재사용
가상 호스팅이 가능하기에, 호스트 헤더가 필수적으로 필요
연결의 재사용, 성능 개선, 서버 부담 감소(TCP 연결 성립/해제 과정 최소화)
HOL Blocking(Head Of Line Blocking)이 발생해 대기 시간이 길어져 성능이 저하될 수 있음

HTTP/2
HTTP/1.x보다 지연 시간을 줄이고 응답시간을 빠르게 함
멀티플렉싱 (여러 개의 스트림을 사용해 송수신하므로 병렬로 여러 요청을 받아 응답 가능)
헤더 압축
서버 푸시 (클라이언트 요청 없이 서버가 바로 리소스를 푸시할 수 있음 -> html을 읽으며 파일 푸시 가능)

HTTPS
애플리케이션 계층과 전송 계층 사이에 신뢰 계층인 SSL/TLS 계층을 넣은 신뢰할 수 있는 HTTP 요청
-> 통신 암호화

SSL(Secure Sockets Layer)/TLS(Transport Layer Security)
전송 계층에서 보안을 제공하는 프로토콜
클라이언트와 서버가 통신할 때 SSL/TLS를 통해 제 3자가 메시지를 도청하거나 변조하지 못하게 막음
보안 세션을 기반으로 데이터를 암호화하며 보안 세션이 만들어질 때 인증 메커니즘, 키 교환 암호화 알고리즘, 해싱 알고리즘 사용

보안 세션
보안의 시작~끝 동안 유지되는 세션

인증 메커니즘
CA (Certificate Authorities) 에서 발급한 인증서(서비스 정보, 공개키, 지문, 디지털 서명)를 기반으로 함
공개키를 클라이언트에 제공하고, 사용자가 접속한 서버가 신뢰할 수 있는 서버임을 보장

암호화 알고리즘
공개 값을 공유 -> 각자의 비밀 값과 혼합해 혼합 값을 공유 -> 해당 값을 또 비밀 값과 혼합 -> PSK(Pre-Shared Key) 생성

해싱 알고리즘
데이터를 더 작고 섞인 조각으로 만드는 알고리즘
SHA-256, SHA-384

TLS 통신 흐름

- 클라이언트에서 사이퍼 슈트(프로토콜, AEAD 사이퍼 모드, 해싱 알고리즘이 나열된 규약)를 서버에 전달
- 서버는 받은 사이퍼 슈트의 암호화 알고리즘 리스트를 제공할 수 있는지 확인
- 제공 가능한 경우, 서버에서 클라이언트로 인증서를 보내는 인증 메커니즘 시작
- 이후, 해싱 알고리즘 등을 활용해 암호화된 데이터 송수신

HTTP/3
QUIC 계층 위에서 UDP 기반으로 돌아감
멀티플렉싱 가능
TCP를 사용하지 않기 때문에 3-way handshake 과정을 거치지 않아 초기 연결 설정에 지연 시간이 감소
